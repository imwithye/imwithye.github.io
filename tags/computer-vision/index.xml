<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Computer Vision on 禅心剑气相思骨</title>
    <link>https://yiwei.dev/tags/computer-vision/</link>
    <description>Recent content in Computer Vision on 禅心剑气相思骨</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 22 Dec 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://yiwei.dev/tags/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>单目视觉vSLAM</title>
      <link>https://yiwei.dev/posts/%E5%8D%95%E6%95%B0%E8%A7%86%E8%A7%89vslam/</link>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yiwei.dev/posts/%E5%8D%95%E6%95%B0%E8%A7%86%E8%A7%89vslam/</guid>
      <description>Matlab 官方提供了完整的单目视觉 vSLAM 的 pipeline，https://www.mathworks.com/help/vision/ug/monocular-visual-simultaneous-localization-and-mapping.html。这里对 Matlab 的这边文章的关键点做一个笔记和讨论，具体的实现可以参考原文文档。
初始化数据集 Matlab 提供了imageDatastore类用于初始化图像存储集合，其接受一个图像的文件夹路径的参数。
imageFolder = [dataFolder,&amp;#39;rgbd_dataset_freiburg3_long_office_household/rgb/&amp;#39;]; imds = imageDatastore(imageFolder); 初始化地图 在 SLAM 管线中，首先我们应该对相机进行标定，相机标定可以用Computer Vision 工具箱中的相机标定工具。如果预先知道了相机的内参，可以通过cameraIntrinsics类直接进行初始化。
% Create a cameraIntrinsics object to store the camera intrinsic parameters. % The intrinsics for the dataset can be found at the following page: % https://vision.in.tum.de/data/datasets/rgbd-dataset/file_formats % Note that the images in the dataset are already undistorted, hence there % is no need to specify the distortion coefficients. focalLength = [535.</description>
    </item>
    
    <item>
      <title>理解光束法平差</title>
      <link>https://yiwei.dev/posts/%E7%90%86%E8%A7%A3%E5%85%89%E6%9D%9F%E6%B3%95%E5%B9%B3%E5%B7%AE/</link>
      <pubDate>Thu, 21 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yiwei.dev/posts/%E7%90%86%E8%A7%A3%E5%85%89%E6%9D%9F%E6%B3%95%E5%B9%B3%E5%B7%AE/</guid>
      <description>在学习计算机视觉的时候，一个无法避开的话题就是光束法平差（Bundle Adjustment）。光束法平差是一个后端优化常用的万金油，其本质是在一组具有误差的点和约束的关系中，寻找一个最优或者最具可能性的解。我在学习的过程中发现，大部分的书籍都在侧重介绍光束法平差的解法，或多或少都涉及大量的数学知识。然而，对于软件工程任务来说，最重要的是理解几个问题：
什么时候使用光束法平差算法？ 光束法平差的输入和输出参数是什么？ 如何从工程角度优化光束法平差？ 由于 Matlab 的计算机视觉工具箱中自带了光束法平差的算法，我们将使用 Matlab 作为例子，来逐步回答上面几个问题。
什么时候使用光束法平差算法？ 线性拟合和最小二乘法 让我们首先来理解线性回归问题，并从中理解最小二乘法的原理。
如果我们有一堆数据，我们可以知道这些数据大概线性相关。比如一辆在高速公路上匀速行驶的汽车，行驶的路程$y$和时间$x$就形成了线性关系，我们可以把这个关系记做$y=ax$，当然我们知道$a$代表汽车的速度。那么我们如何测量这个速度呢？如果我们有一个完美的测量工具，我们只需要测量俩个点，比如时刻$x_0$的路程$y_0$，以及时刻$x_1$的路程$y_1$，我们就很容易求出$a=\frac{y_1-y_0}{x_1-x_0}$。可是所有的测量都有误差，如果我们测量了 100 个观测点，他们大概都分布在$y=ax$附近，但是哪一个$a$的值才是最好的值呢？
蓝色点为观测数据，可以看出数据大致分布在红色线$y=80x$附近 很显然，如果蓝色点是观测数据，从图形上来看，在淡蓝色，红色，黑色三根拟合线中，红色是最佳的拟合线。但是我们如何定量的说明，“最佳”这一概念呢？
我们把时刻$x$作为我们的输入参数，我们的目标是，通过观测数据，我们推导$y$与$x$的关系。通过这个对应关系，我们希望对于任何一个时刻$x$，我们都能预测一个路程$y$。那么，如果我们观测到了$N$个观测数据，我们把他们记做$x_1, x_2, &amp;hellip;, x_N$，和$y_1, y_2, &amp;hellip;, y_N$。那么对于我们的对应关系来说，理论上我们有$ax_1, ax_2, &amp;hellip;, ax_N$，而且我们知道他们应该和我们的观测数据差不多。
我们应该如何定义”最佳“？我们可以说，我们找到的对应关系和我们实际数据的误差最小，那么就是最佳的对应关系。更准确的说，如果$(y_1-ax_1)^2 + (y_2-ax_2)^2 + &amp;hellip; + (y_N-ax_N)^2$最小，那么这一个对应关系的误差就是最小，也就是我们说的最佳对应关系。
这里的所有$x$和$y$都是已知量，即我们的观测数据，所以我们想要误差最小，实际上就变成了一个关于未知数$a$的二次函数，我们找到对应的$a$使得这个二次函数变成最小值。
此时得到的$a$的值就是我们所谓的最佳拟合线。
光束法平差的输入和输出参数是什么？ TBA
如何从工程角度优化光束法平差？ TBA</description>
    </item>
    
  </channel>
</rss>
